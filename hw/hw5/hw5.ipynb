{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize OK\n",
    "from client.api.notebook import Notebook\n",
    "ok = Notebook('hw5.ok')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e0f9b2de18190d9d",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Homework 5: Predicting Housing Prices\n",
    "\n",
    "## Due Date: 11:59pm Monday, March 30\n",
    "\n",
    "### Collaboration Policy\n",
    "\n",
    "Data science is a collaborative activity. While you may talk with others about the homework, we ask that you **write your solutions individually**. If you do discuss the assignments with others please **include their names** in the collaborators cell below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Collaborators:** *list names here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this homework, we will go through the iterative process of specifying, fitting, and analyzing the performance of a  model.  \n",
    "\n",
    "In the first portion of the assignment, we will guide you through some basic exploratory data analysis (EDA), laying out the thought process that leads to certain modeling decisions. Next, you will add a new feature to the dataset, before specifying and fitting a linear model to a few features of the housing data to predict housing prices. Finally, we will analyze the error of the model and brainstorm ways to improve the model's performance.\n",
    "\n",
    "After this homework, you should feel comfortable with the following:\n",
    "\n",
    "1. Simple feature engineering\n",
    "1. Using sklearn to build linear models\n",
    "1. Building a data pipeline using pandas\n",
    "\n",
    "Next week's homework will continue working with this dataset to address more advanced and subtle issues with modeling.\n",
    "\n",
    "## Score Breakdown\n",
    "\n",
    "Question | Points\n",
    "--- | ---\n",
    "[Question 1](#q1) | 3\n",
    "[Question 2](#q2) | 2\n",
    "[Question 3](#q3) | 1\n",
    "[Question 4](#q4) | 1\n",
    "[Question 5](#q5) | 2\n",
    "[Question 6](#q6) | 2\n",
    "[Question 7a](#q7a) | 1\n",
    "[Question 7b](#q7b) | 2\n",
    "[Question 8a](#q8a) | 1\n",
    "[Question 8b](#q8b) | 1\n",
    "[Question 8c](#q8c) | 2\n",
    "[Question 8d](#q8d) | 2\n",
    "Total | 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-62cfd21463535cac",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "from pandas.api.types import CategoricalDtype\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Plot settings\n",
    "plt.rcParams['figure.figsize'] = (12, 9)\n",
    "plt.rcParams['font.size'] = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f68729731e7fe39d",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# The Data\n",
    "\n",
    "The [Ames dataset](http://jse.amstat.org/v19n3/decock.pdf) consists of 2930 records taken from the Ames, Iowa, Assessorâ€™s Office describing houses sold in Ames from 2006 to 2010.  The data set has 23 nominal, 23 ordinal, 14 discrete, and 20 continuous variables (and 2 additional observation identifiers) --- 82 features in total.  An explanation of each variable can be found in the included `codebook.txt` file.  The information was used in computing assessed values for individual residential properties sold in Ames, Iowa from 2006 to 2010.  **Some noise has been added to the actual sale price, so prices will not match official records.**\n",
    "\n",
    "The data are split into training and test sets with 2000 and 930 observations, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e8fea30adc9d489b",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "training_data = pd.read_csv(\"ames_train.csv\")\n",
    "test_data = pd.read_csv(\"ames_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9d6d509b6e854e10",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "As a good sanity check, we should at least verify that the data shape matches the description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c841a2de55691502",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# 2000 observations and 82 features in training data\n",
    "assert training_data.shape == (2000, 82)\n",
    "# 930 observations and 81 features in test data\n",
    "assert test_data.shape == (930, 81)\n",
    "# SalePrice is hidden in the test data\n",
    "assert 'SalePrice' not in test_data.columns.values\n",
    "# Every other column in the test data should be in the training data\n",
    "assert len(np.intersect1d(test_data.columns.values, \n",
    "                          training_data.columns.values)) == 81"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ce9acc2f62c96e59",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "The next order of business is getting a feel for the variables in our data.  The Ames data set contains information that typical homebuyers would want to know.  A more detailed description of each variable is included in `codebook.txt`.  **You should take some time to familiarize yourself with the codebook before moving forward.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4e60a7a0cda5eecf",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "training_data.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ba0f6926b0dafefb",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Part 1: Exploratory Data Analysis\n",
    "\n",
    "In this section, we will make a series of exploratory visualizations and interpret them.\n",
    "\n",
    "Note that we will perform EDA on the **training data** so that information from the test data does not influence our modeling decisions.\n",
    "\n",
    "### Sale Price\n",
    "We begin by examining a [raincloud plot](https://micahallen.org/2018/03/15/introducing-raincloud-plots/amp/?__twitter_impression=true) (a combination of a KDE, a histogram, a strip plot, and a box plot) of our target variable `SalePrice`.  At the same time, we also take a look at some descriptive statistics of this variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-15d483a695655cea",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=2)\n",
    "\n",
    "sns.distplot(\n",
    "    training_data['SalePrice'], \n",
    "    ax=axs[0]\n",
    ")\n",
    "sns.stripplot(\n",
    "    training_data['SalePrice'], \n",
    "    jitter=0.4, \n",
    "    size=3,\n",
    "    ax=axs[1],\n",
    "    alpha=0.3\n",
    ")\n",
    "sns.boxplot(\n",
    "    training_data['SalePrice'],\n",
    "    width=0.3, \n",
    "    ax=axs[1],\n",
    "    showfliers=False,\n",
    ")\n",
    "\n",
    "# Align axes\n",
    "spacer = np.max(training_data['SalePrice']) * 0.05\n",
    "xmin = np.min(training_data['SalePrice']) - spacer\n",
    "xmax = np.max(training_data['SalePrice']) + spacer\n",
    "axs[0].set_xlim((xmin, xmax))\n",
    "axs[1].set_xlim((xmin, xmax))\n",
    "\n",
    "# Remove some axis text\n",
    "axs[0].xaxis.set_visible(False)\n",
    "axs[0].yaxis.set_visible(False)\n",
    "axs[1].yaxis.set_visible(False)\n",
    "\n",
    "# Put the two plots together\n",
    "plt.subplots_adjust(hspace=0)\n",
    "\n",
    "# Adjust boxplot fill to be white\n",
    "axs[1].artists[0].set_facecolor('white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-45e5037c06db70f0",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "training_data['SalePrice'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-592d5f41ebd67ee2",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Question 1  <a name=\"q1\"></a>\n",
    "To check your understanding of the graph and summary statistics above, answer the following `True` or `False` questions:\n",
    "\n",
    "1. The distribution of `SalePrice` in the training set is left-skew.\n",
    "1. The mean of `SalePrice` in the training set is greater than the median.\n",
    "1. At least 25% of the houses in the training set sold for more than \\$200,000.00.\n",
    "\n",
    "*The provided tests for this question do not confirm that you have answered correctly; only that you have assigned each variable to `True` or `False`.*\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1\n",
    "points: 3\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q1-answer",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# These should be True or False\n",
    "q1statement1 = ...\n",
    "q1statement2 = ...\n",
    "q1statement3 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "ok.grade(\"q1\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9e22aac9b45f88e3",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### SalePrice vs Gr_Liv_Area\n",
    "\n",
    "Next, we visualize the association between `SalePrice` and `Gr_Liv_Area`.  The `codebook.txt` file tells us that `Gr_Liv_Area` measures \"above grade (ground) living area square feet.\"\n",
    "\n",
    "This variable represents the square footage of the house excluding anything underground.  Some additional research (into real estate conventions) reveals that this value also excludes the garage space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-02a467f8950ee680",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "sns.jointplot(\n",
    "    x='Gr_Liv_Area', \n",
    "    y='SalePrice', \n",
    "    data=training_data,\n",
    "    stat_func=None,\n",
    "    kind=\"reg\",\n",
    "    ratio=4,\n",
    "    space=0,\n",
    "    scatter_kws={\n",
    "        's': 3,\n",
    "        'alpha': 0.25\n",
    "    },\n",
    "    line_kws={\n",
    "        'color': 'black'\n",
    "    }\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e69fbfdd6101f836",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "There's certainly an association, and perhaps it's linear, but the spread is wider at larger values of both variables.  Also, there are two particularly suspicious houses above 5000 square feet that look too inexpensive for their size.\n",
    "\n",
    "## Question 2 <a name=\"q2\"></a>\n",
    "What are the Parcel Indentification Numbers for the two houses with `Gr_Liv_Area` greater than 5000 sqft?\n",
    "\n",
    "*The provided tests for this question do not confirm that you have answered correctly; only that you have assigned `q2house1` and `q2house2` to two integers that are in the range of PID values.*\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2\n",
    "points: 2\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-eb0c9f329767dfc2",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Hint: You can answer this question in one line\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "ok.grade(\"q2\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-bf7fe5dcd37df6f9",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Question 3 <a name=\"q3\"></a>\n",
    "\n",
    "The codebook tells us how to manually inspect the houses using an online database called Beacon. These two houses are true outliers in this data set: they aren't the same time of entity as the rest. They were partial sales, priced far below market value. If you would like to inspect the valuations, follow the directions at the bottom of the codebook to access Beacon and look up houses by PID.\n",
    "\n",
    "For this assignment, we will remove these outliers from the data. Write a function `remove_outliers` that removes outliers from a data set based off a threshold value of a variable.  For example, `remove_outliers(training_data, 'Gr_Liv_Area', upper=5000)` should return a data frame with only observations that satisfy `Gr_Liv_Area` less than 5000.\n",
    "\n",
    "*The provided tests check that training_data was updated correctly, so that future analyses are not corrupted by a mistake. However, the provided tests do not check that you have implemented remove_outliers correctly so that it works with any data, variable, lower, and upper bound.*\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9186ec2ca053d0aa",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def remove_outliers(data, variable, lower=-np.inf, upper=np.inf):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "      data (data frame): the table to be filtered\n",
    "      variable (string): the column with numerical outliers\n",
    "      lower (numeric): observations with values lower than or equal to this will be removed\n",
    "      upper (numeric): observations with values higher than or equal to this will be removed\n",
    "    \n",
    "    Output:\n",
    "      a winsorized data frame with outliers removed\n",
    "      \n",
    "    Note: This function should not change mutate the contents of data.\n",
    "    \"\"\"  \n",
    "    ...\n",
    "\n",
    "training_data = remove_outliers(training_data, 'Gr_Liv_Area', upper=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "ok.grade(\"q3\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# Part 2: Feature Engineering\n",
    "\n",
    "In this section we will create a new feature out of existing ones through a simple data transformation.\n",
    "\n",
    "### Bathrooms\n",
    "\n",
    "Let's create a groundbreaking new feature. Due to recent advances in Universal WC Enumeration Theory, we now know that Total Bathrooms can be calculated as:\n",
    "\n",
    "$$ \\text{TotalBathrooms}=(\\text{BsmtFullBath} + \\text{FullBath}) + \\dfrac{1}{2}(\\text{BsmtHalfBath} + \\text{HalfBath})$$\n",
    "\n",
    "The actual proof is beyond the scope of this class, but we will use the result in our model.\n",
    "\n",
    "## Question 4 <a name=\"q4\"></a>\n",
    "\n",
    "Write a function `add_total_bathrooms(data)` that returns a copy of `data` with an additional column called `TotalBathrooms` computed by the formula above.  **Treat missing values as zeros**.  Remember that you can make use of vectorized code here; you shouldn't need any `for` statements. \n",
    "\n",
    "*The provided tests check that you answered correctly, so that future analyses are not corrupted by a mistake.*\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q4\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_total_bathrooms(data):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "      data (data frame): a data frame containing at least 4 numeric columns \n",
    "            Bsmt_Full_Bath, Full_Bath, Bsmt_Half_Bath, and Half_Bath\n",
    "    \"\"\"\n",
    "    with_bathrooms = data.copy()\n",
    "    bath_vars = ['Bsmt_Full_Bath', 'Full_Bath', 'Bsmt_Half_Bath', 'Half_Bath']\n",
    "    weights = pd.Series([1, 1, 0.5, 0.5], index=bath_vars)\n",
    "    ...\n",
    "    return with_bathrooms\n",
    "\n",
    "training_data = add_total_bathrooms(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "ok.grade(\"q4\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Question 5 <a name=\"q5\"></a>\n",
    "\n",
    "Create a visualization that clearly and succintly shows that `TotalBathrooms` is associated with `SalePrice`. Your visualization should avoid overplotting.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q5\n",
    "points: 2\n",
    "manual: True\n",
    "format: image\n",
    "-->\n",
    "<!-- EXPORT TO PDF format:image -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-5ffdfab3f8801658",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Part 3: Modeling\n",
    "\n",
    "We've reached the point where we can specify a model. But first, we will load a fresh copy of the data, just in case our code above produced any undesired side-effects. Run the cell below to store a fresh copy of the data from `ames_train.csv` in a dataframe named `full_data`. We will also store the number of rows in `full_data` in the variable `full_data_len`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a fresh copy of the data and get its length\n",
    "full_data = pd.read_csv(\"ames_train.csv\")\n",
    "full_data_len = len(full_data)\n",
    "full_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Question 6 <a name=\"q6\"></a>\n",
    "\n",
    "Now, let's split the data set into a training set and test set. We will use the training set to fit our model's parameters, and we will use the test set to estimate how well our model will perform on unseen data drawn from the same distribution. If we used all the data to fit our model, we would not have a way to estimate model performance on unseen data.\n",
    "\n",
    "\"Don't we already have a test set in `ames_test.csv`?\" you might wonder. The sale prices for `ames_test.csv` aren't provided, so we're constructing our own test set for which we know the outputs.\n",
    "\n",
    "In the cell below, split the data in `full_data` into two DataFrames named `train` and `test`. Let `train` contain 80% of the data, and let `test` contain the remaining 20% of the data. \n",
    "\n",
    "To do this, first create two NumPy arrays named `train_indices` and `test_indices`. `train_indices` should contain a *random* 80% of the indices in `full_data`, and `test_indices` should contain the remaining 20% of the indices. Then, use these arrays to index into `full_data` to create your final `train` and `test` DataFrames.\n",
    "\n",
    "*The provided tests check that you not only answered correctly, but ended up with the exact same train/test split as our reference implementation. Later testing is easier this way.*\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q6\n",
    "points: 2\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-700027ec3c0adc57",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# This makes the train-test split in this section reproducible across different runs \n",
    "# of the notebook. You do not need this line to run train_test_split in general\n",
    "np.random.seed(1337)\n",
    "shuffled_indices = np.random.permutation(full_data_len)\n",
    "\n",
    "# Set train_indices to the first 80% of shuffled_indices and and test_indices to the rest.\n",
    "train_indices = ...\n",
    "test_indices = ...\n",
    "\n",
    "# Create train and test` by indexing into `full_data` using \n",
    "# `train_indices` and `test_indices`\n",
    "train = ...\n",
    "test = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "ok.grade(\"q6\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-acdc861fd11912e9",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Reusable Pipeline\n",
    "\n",
    "Throughout this assignment, you should notice that your data flows through a single processing pipeline several times.  From a software engineering perspective, it's best to define functions/methods that can apply the pipeline to any dataset.  We will now encapsulate our entire pipeline into a single function `process_data_gm`.  gm is shorthand for \"guided model\". We select a handful of features to use from the many that are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-2fe1d82b2c19d1fa",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def select_columns(data, *columns):\n",
    "    \"\"\"Select only columns passed as arguments.\"\"\"\n",
    "    return data.loc[:, columns]\n",
    "\n",
    "def process_data_gm(data):\n",
    "    \"\"\"Process the data for a guided model.\"\"\"\n",
    "    data = remove_outliers(data, 'Gr_Liv_Area', upper=5000)\n",
    "    \n",
    "    # Transform Data, Select Features\n",
    "    data = add_total_bathrooms(data)\n",
    "    data = select_columns(data, \n",
    "                          'SalePrice', \n",
    "                          'Gr_Liv_Area', \n",
    "                          'Garage_Area',\n",
    "                          'TotalBathrooms',\n",
    "                         )\n",
    "    \n",
    "    # Return predictors and response variables separately\n",
    "    X = data.drop(['SalePrice'], axis = 1)\n",
    "    y = data.loc[:, 'SalePrice']\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can use `process_data_gm1` to clean our data, select features, and add our `TotalBathrooms` feature all in one step! This function also splits our data into `X`, a matrix of features, and `y`, a vector of sale prices. \n",
    "\n",
    "Run the cell below to feed our training and test data through the pipeline, generating `X_train`, `y_train`, `X_test`, and `y_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-process our training and test data in exactly the same way\n",
    "# Our functions make this very easy!\n",
    "X_train, y_train = process_data_gm(train)\n",
    "X_test, y_test = process_data_gm(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-41994ca25b31660e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Fitting Our First Model\n",
    "\n",
    "We are finally going to fit a model!  The model we will fit can be written as follows:\n",
    "\n",
    "$$\\text{SalePrice} = \\theta_0 + \\theta_1 \\cdot \\text{Gr_Liv_Area} + \\theta_2 \\cdot \\text{Garage_Area} + \\theta_3 \\cdot \\text{TotalBathrooms}$$\n",
    "\n",
    "In vector notation, the same equation would be written:\n",
    "\n",
    "$$y = \\vec\\theta \\cdot \\vec{x}$$\n",
    "\n",
    "where $y$ is the SalePrice, $\\vec\\theta$ is a vector of all fitted weights, and $\\vec{x}$ contains a 1 for the bias followed by each of the feature values.\n",
    "\n",
    "**Note:** Notice that all of our variables are continuous, except for `TotalBathrooms`, which takes on discrete ordered values (0, 0.5, 1, 1.5, ...). In this homework, we'll treat `TotalBathrooms` as a continuous quantitative variable in our model, but this might not be the best choice. The next homework may revisit the issue.\n",
    "\n",
    "## Question 7a <a name=\"q7a\"></a>\n",
    "\n",
    "We will use a [`sklearn.linear_model.LinearRegression`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html) object as our linear model. In the cell below, create a `LinearRegression` object and name it `linear_model`.\n",
    "\n",
    "**Hint:** See the `fit_intercept` parameter and make sure it is set appropriately. The intercept of our model corresponds to $\\theta_0$ in the equation above.\n",
    "\n",
    "*The provided tests check that you answered correctly, so that future analyses are not corrupted by a mistake.*\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q7a\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model as lm\n",
    "\n",
    "linear_model = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "ok.grade(\"q7a\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Question 7b <a name=\"q7b\"></a>\n",
    "\n",
    "Now, remove the commenting and fill in the ellipses `...` below with `X_train`, `y_train`, `X_test`, or `y_test`.\n",
    "\n",
    "With the ellipses filled in correctly, the code below should fit our linear model to the training data and generate the predicted sale prices for both the training and test datasets.\n",
    "\n",
    "*The provided tests check that you answered correctly, so that future analyses are not corrupted by a mistake.*\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q7b\n",
    "points: 2\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-1be99eea86f6cf57",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Uncomment the lines below and fill in the ... with X_train, y_train, X_test, or y_test.\n",
    "# linear_model.fit(..., ...)\n",
    "# y_fitted = linear_model.predict(...)\n",
    "# y_predicted = linear_model.predict(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "ok.grade(\"q7b\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Question 8a <a name=\"q8a\"></a>\n",
    "\n",
    "Is our linear model any good at predicting house prices? Let's measure the quality of our model by calculating the Root-Mean-Square Error (RMSE) between our predicted house prices and the true prices stored in `SalePrice`.\n",
    "\n",
    "$$\\text{RMSE} = \\sqrt{\\dfrac{\\sum_{\\text{houses in test set}}(\\text{actual price of house} - \\text{predicted price of house})^2}{\\text{# of houses in data set}}}$$\n",
    "\n",
    "In the cell below, write a function named `rmse` that calculates the RMSE of a model.\n",
    "\n",
    "**Hint:** Make sure you are taking advantage of vectorized code. This question can be answered without any `for` statements.\n",
    "\n",
    "*The provided tests check that you answered correctly, so that future analyses are not corrupted by a mistake.*\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q8a\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-96600fa98a6c2e97",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def rmse(actual, predicted):\n",
    "    \"\"\"\n",
    "    Calculates RMSE from actual and predicted values\n",
    "    Input:\n",
    "      actual (1D array): vector of actual values\n",
    "      predicted (1D array): vector of predicted/fitted values\n",
    "    Output:\n",
    "      a float, the root-mean square error\n",
    "    \"\"\"\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "ok.grade(\"q8a\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Question 8b <a name=\"q8b\"></a>\n",
    "\n",
    "Now use your `rmse` function to calculate the training error and test error in the cell below.\n",
    "\n",
    "*The provided tests for this question do not confirm that you have answered correctly; only that you have assigned each variable to a non-negative number.*\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q8b\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_error = ...\n",
    "test_error = ...\n",
    "(training_error, test_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "ok.grade(\"q8b\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Question 8c <a name=\"q8c\"></a>\n",
    "\n",
    "How much does including `TotalBathrooms` as a predictor reduce the RMSE of the model on the test set? That is, what's the difference between the RSME of a model that only includes `Gr_Liv_Area` and `Garage_Area` versus one that includes all three predictors?\n",
    "\n",
    "*The provided tests for this question do not confirm that you have answered correctly; only that you have assigned the answer variable to a non-negative number.*\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q8c\n",
    "points: 2\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_error_difference = test_error_no_bath - test_error\n",
    "test_error_difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "ok.grade(\"q8c\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a359da2dda38fcdd",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Residual Plots\n",
    "\n",
    "One way of understanding the performance (and appropriateness) of a model is through a residual plot. Run the cell below to plot the actual sale prices against the residuals of the model for the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4d79f42d60b94fca",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "residuals = y_test - y_predicted\n",
    "ax = sns.regplot(y_test, residuals)\n",
    "ax.set_xlabel('Sale Price (Test Data)')\n",
    "ax.set_ylabel('Residuals (Actual Price - Predicted Price)')\n",
    "ax.set_title(\"Residuals vs. Sale Price on Test Data\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Ideally, we would see a horizontal line of points at 0 (perfect prediction!). The next best thing would be a homogenous set of points centered at 0. \n",
    "\n",
    "But alas, our simple model is probably too simple. The most expensive homes are systematically more expensive than our prediction. \n",
    "\n",
    "## Question 8d <a name=\"q8c\"></a>\n",
    "\n",
    "What changes could you make to your linear model to improve its accuracy and lower the test error? Suggest at least two things you could try in the cell below, and carefully explain how each change could potentially improve your model's accuracy.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q8d\n",
    "points: 2\n",
    "manual: True\n",
    "-->\n",
    "<!-- EXPORT TO PDF -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Write your answer here, replacing this text.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# Submit\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output.\n",
    "**Please save before submitting!**\n",
    "\n",
    "<!-- EXPECT 2 EXPORTED QUESTIONS -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Save your notebook first, then run this cell to submit.\n",
    "import jassign.to_pdf\n",
    "jassign.to_pdf.generate_pdf('hw5.ipynb', 'hw5.pdf')\n",
    "ok.submit()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
