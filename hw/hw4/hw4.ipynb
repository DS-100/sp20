{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize OK\n",
    "from client.api.notebook import Notebook\n",
    "ok = Notebook('hw4.ok')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "intro",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "# Homework 4: Trump, Twitter, and Text\n",
    "\n",
    "## Due Date: Monday 03/02, 11:59 pm PST\n",
    "\n",
    "Welcome to the fourth homework assignment of Data 100/200! In this assignment, we will work with Twitter data in order to analyze Donald Trump's tweets.\n",
    "\n",
    "**Collaboration Policy**\n",
    "\n",
    "Data science is a collaborative activity. While you may talk with others about the homework, we ask that you **write your solutions individually**. If you do discuss the assignments with others please **include their names** below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Collaborators**: *list collaborators here*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "import",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Run this cell to set up your notebook\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import zipfile\n",
    "\n",
    "# Ensure that Pandas shows at least 280 characters in columns, so we can see full tweets\n",
    "pd.set_option('max_colwidth', 280)\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('fivethirtyeight')\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "sns.set_context(\"talk\")\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score Breakdown\n",
    "\n",
    "Question | Points\n",
    "--- | ---\n",
    "0 | 2\n",
    "1 | 2\n",
    "2 | 1\n",
    "3 | 2\n",
    "4a | 1\n",
    "4b | 2\n",
    "4c | 2\n",
    "4d | 1\n",
    "5a | 1\n",
    "5b | 1\n",
    "5c | 1\n",
    "5d | 1\n",
    "5e | 1\n",
    "5f | 2\n",
    "5g | 2\n",
    "5h | 2\n",
    "6a | 1\n",
    "6b | 1\n",
    "7a | 2\n",
    "7b | 1\n",
    "Total | 29"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before we start ##\n",
    "Before we actually analyze the tweets, you might find this article interesting. It contains some recent news about President Trump setting yet another Twitter record.\n",
    "https://www.usatoday.com/story/news/politics/2019/10/01/donald-trump-sets-twitter-record-amid-impeachment-inquiry-over-ukraine/3828507002/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q3",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "---\n",
    "# Part 1: Importing the Data\n",
    "\n",
    "We will use the `fetch_and_cache` utility to download the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "download-data",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Download the dataset\n",
    "from ds100_utils import fetch_and_cache\n",
    "data_url = 'http://www.ds100.org/fa19/assets/datasets/hw4-realdonaldtrump_tweets.json.zip'\n",
    "file_name = 'hw4-realdonaldtrump_tweets.json.zip'\n",
    "\n",
    "dest_path = fetch_and_cache(data_url=data_url, file=file_name)\n",
    "print(f'Located at {dest_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've downloaded the tweets, let's unzip them and load them into our notebook. Run the cell below to unzip and read tweets from the json file into a list named `all_tweets`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unzip the dataset\n",
    "my_zip = zipfile.ZipFile(dest_path, 'r')\n",
    "with my_zip.open('hw4-realdonaldtrump_tweets.json', 'r') as f:\n",
    "    all_tweets = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "formatting-note",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "Here is what a typical tweet from `all_tweets` looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "pprint-old-tweets",
     "locked": true,
     "schema_version": 2,
     "solution": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from pprint import pprint # to get a more easily-readable view.\n",
    "pprint(all_tweets[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Question 0\n",
    "Why might someone be interested in doing data analysis on the President’s tweets? Name one person or entity which might be interested in this kind of analysis. Then, give two reasons why a data analysis of the President's tweets might be interesting or useful for them. Answer in 2-3 sentences.\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q0\n",
    "points: 2\n",
    "manual: true\n",
    "-->\n",
    "<!-- EXPORT TO PDF -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Write your answer here, replacing this text.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "q3b",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "## Question 1\n",
    "\n",
    "Construct a DataFrame called `trump` containing data from all the tweets stored in `all_tweets`. The index of the DataFrame should be the ID of each tweet (looks something like `907698529606541312`). It should have these columns:\n",
    "\n",
    "- `time`: The time the tweet was created encoded as a datetime object. (Use `pd.to_datetime` to encode the timestamp.)\n",
    "- `source`: The source device of the tweet.\n",
    "- `text`: The text of the tweet.\n",
    "- `retweet_count`: The retweet count of the tweet. \n",
    "\n",
    "Finally, **the resulting DataFrame should be sorted by the index.**\n",
    "\n",
    "**Warning:** *Some tweets will store the text in the `text` field and other will use the `full_text` field.*\n",
    "\n",
    "**Hint: You might want to explicitly specify the columns and indices using** `pd.Dataframe()`.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1\n",
    "points: 2\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q3b-answer",
     "locked": false,
     "schema_version": 2,
     "solution": true
    },
    "scrolled": true,
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "trump = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "ok.grade(\"q1\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "question4",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "---\n",
    "# Part 2: Tweet Source Analysis\n",
    "\n",
    "In the following questions, we are going to find out the charateristics of Trump tweets and the devices used for the tweets.\n",
    "\n",
    "First let's examine the source field:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "unique-sources",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "trump['source'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "q4a",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "## Question 2\n",
    "\n",
    "Notice how sources like \"Twitter for Android\" or \"Instagram\" are surrounded by HTML tags. In the cell below, clean up the `source` field by removing the HTML tags from each `source` entry.\n",
    "\n",
    "**Hints:** \n",
    "* Use `trump['source'].str.replace` along with a regular expression.\n",
    "* You may find it helpful to experiment with regular expressions at [regex101.com](https://regex101.com/).\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q4a-answer",
     "locked": false,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "## Uncomment and complete\n",
    "# trump['source'] = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "ok.grade(\"q2\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "note-about-device-usage",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "In the following plot, we see that there are two device types that are more commonly used than others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "device-usage-plot",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "trump['source'].value_counts().plot(kind=\"bar\")\n",
    "plt.ylabel(\"Number of Tweets\")\n",
    "plt.title(\"Number of Tweets by Source\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q5",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "## Question 3\n",
    "\n",
    "Now that we have cleaned up the `source` field, let's now look at which device Trump has used over the entire time period of this dataset.\n",
    "\n",
    "To examine the distribution of dates we will convert the date to a fractional year that can be plotted as a distribution.\n",
    "\n",
    "(Code borrowed from this [link](https://stackoverflow.com/questions/6451655/python-how-to-convert-datetime-dates-to-decimal-years))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "fractional-year",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "def year_fraction(date):\n",
    "    start = datetime.date(date.year, 1, 1).toordinal()\n",
    "    year_length = datetime.date(date.year+1, 1, 1).toordinal() - start\n",
    "    return date.year + float(date.toordinal() - start) / year_length\n",
    "\n",
    "trump['year'] = trump['time'].apply(year_fraction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "q5a",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "Now, use `sns.distplot` to overlay the distributions of Trump's 2 most frequently used web technologies over the years. Your final plot should look similar to the plot below:\n",
    "\n",
    "<img src=\"images/source_years_q3.png\" width=\"600px\" />\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3\n",
    "points: 2\n",
    "manual: true\n",
    "-->\n",
    "<!-- EXPORT TO PDF -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "q5a-answer",
     "locked": false,
     "points": 2,
     "schema_version": 2,
     "solution": true
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q4b",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "## Question 4\n",
    "\n",
    "\n",
    "Is there a difference between Trump's tweet behavior across these devices? We will attempt to answer this question in our subsequent analysis.\n",
    "\n",
    "First, we'll take a look at whether Trump's tweets from an Android device come at different times than his tweets from an iPhone. Note that Twitter gives us his tweets in the [UTC timezone](https://www.wikiwand.com/en/List_of_UTC_time_offsets) (notice the `+0000` in the first few tweets)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "tweet-created-at",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "for tweet in all_tweets[:3]:\n",
    "    print(tweet['created_at'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "convert-to-est-justification",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "We'll convert the tweet times to US Eastern Time, the timezone of New York and Washington D.C., since those are the places we would expect the most tweet activity from Trump."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "convert-to-est",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "trump['est_time'] = (\n",
    "    trump['time'].dt.tz_convert(\"EST\") # Convert to Eastern Time\n",
    ")\n",
    "trump.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "need-to-do",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### Question 4a\n",
    "\n",
    "Add a column called `hour` to the `trump` table which contains the hour of the day as floating point number computed by:\n",
    "\n",
    "$$\n",
    "\\text{hour} + \\frac{\\text{minute}}{60} + \\frac{\\text{second}}{60^2}\n",
    "$$\n",
    "\n",
    "* **Hint:** See the cell above for an example of working with [dt accessors](https://pandas.pydata.org/pandas-docs/stable/getting_started/basics.html#basics-dt-accessors). You should use the `est_time` column to calculate the hour.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q4a\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q4b-answer",
     "locked": false,
     "schema_version": 2,
     "solution": true
    },
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "trump['hour'] = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "ok.grade(\"q4a\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "q4c",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### Question 4b\n",
    "\n",
    "Use this data along with the seaborn `distplot` function to examine the distribution over hours of the day in eastern time that Trump tweets on each device for the 2 most commonly used devices.  Your final plot should look similar to the following:\n",
    "\n",
    "<img src=\"images/device_hour4b.png\" width=\"600px\" />\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q4b\n",
    "points: 2\n",
    "manual: true\n",
    "-->\n",
    "<!-- EXPORT TO PDF -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "q4c-answer",
     "locked": false,
     "points": 2,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### make your plot here\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "q4d",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### Question 4c\n",
    "\n",
    "According to [this Verge article](https://www.theverge.com/2017/3/29/15103504/donald-trump-iphone-using-switched-android), Donald Trump switched from an Android to an iPhone sometime in March 2017.\n",
    "\n",
    "Let's see if this information significantly changes our plot. Create a figure similar to your figure from question 4b, but this time, only use tweets that were tweeted before 2017. Your plot should look similar to the following:\n",
    "\n",
    "<img src=\"images/device_hour4c.png\" width=\"600px\" />\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q4c\n",
    "points: 2\n",
    "manual: true\n",
    "-->\n",
    "<!-- EXPORT TO PDF -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-9d60149ec24272e3",
     "locked": false,
     "points": 0,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### make your plot here\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 4d\n",
    "\n",
    "During the campaign, it was theorized that Donald Trump's tweets from Android devices were written by him personally, and the tweets from iPhones were from his staff. Does your figure give support to this theory? What kinds of additional analysis could help support or reject this claim?\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q4d\n",
    "points: 1\n",
    "manual: true\n",
    "-->\n",
    "<!-- EXPORT TO PDF -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "q4d-answer",
     "locked": false,
     "points": 1,
     "schema_version": 2,
     "solution": true
    },
    "tags": [
     "student",
     "written"
    ]
   },
   "source": [
    "*Write your answer here, replacing this text.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q6-header",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "---\n",
    "# Part 3: Sentiment Analysis\n",
    "\n",
    "It turns out that we can use the words in Trump's tweets to calculate a measure of the sentiment of the tweet. For example, the sentence \"I love America!\" has positive sentiment, whereas the sentence \"I hate taxes!\" has a negative sentiment. In addition, some words have stronger positive / negative sentiment than others: \"I love America.\" is more positive than \"I like America.\"\n",
    "\n",
    "We will use the [VADER (Valence Aware Dictionary and sEntiment Reasoner)](https://github.com/cjhutto/vaderSentiment) lexicon to analyze the sentiment of Trump's tweets. VADER is a lexicon and rule-based sentiment analysis tool that is specifically attuned to sentiments expressed in social media which is great for our usage.\n",
    "\n",
    "The VADER lexicon gives the sentiment of individual words. Run the following cell to show the first few rows of the lexicon:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "head-vader",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "print(''.join(open(\"vader_lexicon.txt\").readlines()[:10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the lexicon contains emojis too! Each row contains a word and the *polarity* of that word, measuring how positive or negative the word is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "q6a-header",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "## Question 5\n",
    "\n",
    "The creators of VADER describe the tool’s assessment of polarity, or “compound score,” in the following way:\n",
    "\n",
    "“The compound score is computed by summing the valence scores of each word in the lexicon, adjusted according to the rules, and then normalized to be between -1 (most extreme negative) and +1 (most extreme positive). This is the most useful metric if you want a single unidimensional measure of sentiment for a given sentence. Calling it a 'normalized, weighted composite score' is accurate.”\n",
    "\n",
    "As you can see, VADER doesn't \"read\" sentences, but works by parsing sentences into words assigning a preset generalized score from their testing sets to each word separately. \n",
    "\n",
    "VADER relies on humans to stabilize its scoring. The creators use Amazon Mechanical Turk, a crowdsourcing survey platform, to train its model. Its training set of data consists of a small corpus of tweets, New York Times editorials and news articles, Rotten Tomatoes reviews, and Amazon product reviews, tokenized using the natural language toolkit (NLTK). Each word in each dataset was reviewed and rated by at least 20 trained individuals who had signed up to work on these tasks through Mechanical Turk. \n",
    "\n",
    "### Question 5a\n",
    "\n",
    "Given the above information about how VADER works, name one advantage and one disadvantage of using VADER in our analysis. \n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q5a\n",
    "points: 1\n",
    "manual: true\n",
    "-->\n",
    "<!-- EXPORT TO PDF -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Write your answer here, replacing this text.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 5b\n",
    "Are there circumstances (e.g. certain kinds of language or data) when you might not want to use VADER? Please answer \"Yes,\" or \"No,\" and provide 1 reason for your answer. \n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q5b\n",
    "points: 1\n",
    "manual: true\n",
    "-->\n",
    "<!-- EXPORT TO PDF -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Write your answer here, replacing this text.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 5c\n",
    "\n",
    "Read `vader_lexicon.txt` into a DataFrame called `sent`. The index of the DataFrame should be the words in the lexicon. `sent` should have one column named `polarity`, storing the polarity of each word.\n",
    "\n",
    "* **Hint:** The `pd.read_csv` function may help here. Since the file is tab-separated, be sure to set `sep='\\t'` in your call to `pd.read_csv`. \n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q5c\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q6a1",
     "locked": false,
     "schema_version": 2,
     "solution": true
    },
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "sent = ...\n",
    "sent.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "ok.grade(\"q5c\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "q6b-header",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### Question 5d\n",
    "\n",
    "Now, let's use this lexicon to calculate the overall sentiment for each of Trump's tweets. Here's the basic idea:\n",
    "\n",
    "1. For each tweet, find the sentiment of each word.\n",
    "2. Calculate the sentiment of each tweet by taking the sum of the sentiments of its words.\n",
    "\n",
    "First, let's lowercase the text in the tweets since the lexicon is also lowercase. Set the `text` column of the `trump` DataFrame to be the lowercased text of each tweet.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q5d\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q6b-answer",
     "locked": false,
     "schema_version": 2,
     "solution": true
    },
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "...\n",
    "trump.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "ok.grade(\"q5d\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "q6c-header",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### Question 5e\n",
    "\n",
    "Now, let's get rid of punctuation since it will cause us to fail to match words. Create a new column called `no_punc` in the `trump` DataFrame to be the lowercased text of each tweet with all punctuation replaced by a single space. We consider punctuation characters to be *any character that isn't a Unicode word character or a whitespace character*. You may want to consult the Python documentation on regexes for this problem.\n",
    "\n",
    "(Why don't we simply remove punctuation instead of replacing with a space? See if you can figure this out by looking at the tweet data.)\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q5e\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q6c",
     "locked": false,
     "schema_version": 2,
     "solution": true
    },
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "# Save your regex in punct_re\n",
    "punct_re = r''\n",
    "trump['no_punc'] = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "ok.grade(\"q5e\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "q6d-header",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### Question 5f\n",
    "\n",
    "Now, let's convert the tweets into what's called a [*tidy format*](https://cran.r-project.org/web/packages/tidyr/vignettes/tidy-data.html) to make the sentiments easier to calculate. Use the `no_punc` column of `trump` to create a table called `tidy_format`. The index of the table should be the IDs of the tweets, repeated once for every word in the tweet. It has two columns:\n",
    "\n",
    "1. `num`: The location of the word in the tweet. For example, if the tweet was \"i love america\", then the location of the word \"i\" is 0, \"love\" is 1, and \"america\" is 2.\n",
    "2. `word`: The individual words of each tweet.\n",
    "\n",
    "The first few rows of our `tidy_format` table look like:\n",
    "\n",
    "<table border=\"1\" class=\"dataframe\">\n",
    "  <thead>\n",
    "    <tr style=\"text-align: right;\">\n",
    "      <th></th>\n",
    "      <th>num</th>\n",
    "      <th>word</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th>894661651760377856</th>\n",
    "      <td>0</td>\n",
    "      <td>i</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>894661651760377856</th>\n",
    "      <td>1</td>\n",
    "      <td>think</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>894661651760377856</th>\n",
    "      <td>2</td>\n",
    "      <td>senator</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>894661651760377856</th>\n",
    "      <td>3</td>\n",
    "      <td>blumenthal</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>894661651760377856</th>\n",
    "      <td>4</td>\n",
    "      <td>should</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "\n",
    "**Note that your DataFrame may look different from the one above.** However, you can double check that your tweet with ID `894661651760377856` has the same rows as ours. Our tests don't check whether your table looks exactly like ours.\n",
    "\n",
    "As usual, try to avoid using any for loops. Our solution uses a chain of 5 methods on the `trump` DataFrame, albeit using some rather advanced Pandas hacking.\n",
    "\n",
    "* **Hint 1:** Try looking at the `expand` argument to pandas' `str.split`.\n",
    "\n",
    "* **Hint 2:** Try looking at the `stack()` method.\n",
    "\n",
    "* **Hint 3:** Try looking at the `level` parameter of the `reset_index` method.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q5f\n",
    "points: 2\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q6d-answer",
     "locked": false,
     "schema_version": 2,
     "solution": true
    },
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "tidy_format = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "ok.grade(\"q5f\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "q6e-header",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### Question 5g\n",
    "\n",
    "Now that we have this table in the tidy format, it becomes much easier to find the sentiment of each tweet: we can join the table with the lexicon table. \n",
    "\n",
    "Add a `polarity` column to the `trump` table.  The `polarity` column should contain the sum of the sentiment polarity of each word in the text of the tweet.\n",
    "\n",
    "**Hints:** \n",
    "* You will need to merge the `tidy_format` and `sent` tables and group the final answer.\n",
    "* If certain words are not found in the `sent` table, set their polarities to 0.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q5g\n",
    "points: 2\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q6e",
     "locked": false,
     "schema_version": 2,
     "solution": true
    },
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "trump['polarity'] = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "ok.grade(\"q5g\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "a-note-on-vader",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "Now we have a measure of the sentiment of each of his tweets! Note that this calculation is rather basic; you can read over the VADER readme to understand a more robust sentiment analysis.\n",
    "\n",
    "Now, run the cells below to see the most positive and most negative tweets from Trump in your dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "negative-tweets",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "print('Most negative tweets:')\n",
    "for t in trump.sort_values('polarity').head()['text']:\n",
    "    print('\\n  ', t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "postive-tweets",
     "locked": true,
     "schema_version": 2,
     "solution": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Most positive tweets:')\n",
    "for t in trump.sort_values('polarity', ascending=False).head()['text']:\n",
    "    print('\\n  ', t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Question 5h\n",
    "\n",
    "Read the 5 most positive and 5 most negative tweets. Do you think these tweets are accurately represented by their polarity scores?\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q5h\n",
    "points: 1\n",
    "manual: true\n",
    "-->\n",
    "<!-- EXPORT TO PDF -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Write your answer here, replacing this text.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "q6g",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "## Question 6\n",
    "\n",
    "Now, let's try looking at the distributions of sentiments for tweets containing certain keywords.\n",
    "\n",
    "### Question 6a\n",
    "\n",
    "In the cell below, create a single plot showing both the distribution of tweet sentiments for tweets containing `nytimes`, as well as the distribution of tweet sentiments for tweets containing `fox`.\n",
    "\n",
    "Be sure to label your axes and provide a title and legend. Be sure to use different colors for `fox` and `nytimes`.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q6a\n",
    "points: 1\n",
    "manual: true\n",
    "-->\n",
    "<!-- EXPORT TO PDF -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "q6g-answer",
     "locked": false,
     "points": 1,
     "schema_version": 2,
     "solution": true
    },
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "comment-on-faux-news",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### Question 6b\n",
    "Comment on what you observe in the plot above. Can you find another pair of keywords that lead to interesting plots? Describe what makes the plots interesting. (If you modify your code in 6a, remember to change the words back to `nytimes` and `fox` before submitting for grading).\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q6b\n",
    "points: 1\n",
    "manual: true\n",
    "-->\n",
    "<!-- EXPORT TO PDF -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "q6g-written",
     "locked": false,
     "points": 1,
     "schema_version": 2,
     "solution": true
    }
   },
   "source": [
    "*Write your answer here, replacing this text.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's see whether there's a difference in sentiment for tweets with hashtags and those without."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 7a\n",
    "First, we'll need to write some regex that can detect whether a tweet contains a hashtag or a link. We say that:\n",
    "\n",
    "- A tweet is a retweet if it has the string 'rt' anywhere in the tweet if it is preceeded and followed by a non-word character (the start and end of the string count as non-word characters).\n",
    "- A tweet has a hashtag if it has the character '#' anywhere in the tweet followed by a letter.\n",
    "- A tweet contains a link or a picture if it has `http` anywhere in the tweet\n",
    "\n",
    "(You can check out Trump's Twitter for why these criteria are true).\n",
    "\n",
    "In the cell below, assign `rt_re` to a regex pattern that identifies retweets and `hash_link_re` to a regex pattern that identifies tweets with hashtags or links.\n",
    "\n",
    "**Hints**: \n",
    "- Be sure to precede your regex pattern with `r` to make it a raw string (Ex: `r'pattern'`). To find out more, you can read the first paragraph of the [documentation](https://docs.python.org/2/library/re.html).\n",
    "- You may find using regex word boundaries helpful for one of your patterns. \n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q7a\n",
    "points: 2\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_re = ...\n",
    "hash_link_re = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "ok.grade(\"q7a\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7b\n",
    "Let's see whether there's a difference in sentiments for tweets with hashtags/links and those without. \n",
    "\n",
    "Run the cell below to see a distribution of tweet sentiments based on whether a tweet contains a hashtag or link."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(trump[trump['text'].str.contains(hash_link_re)]['polarity'],label='hashtag or link');\n",
    "sns.distplot(trump[~trump['text'].str.contains(hash_link_re)]['polarity'],label='no hashtag or link');\n",
    "plt.xlim(-10, 10);\n",
    "plt.ylim(0, 0.4);\n",
    "plt.title('Distribution of Tweet Polarities (hashtag/link vs none)');\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "What do you notice about the distributions? Answer in 1-2 sentences.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q7b\n",
    "points: 1\n",
    "manual: true\n",
    "-->\n",
    "<!-- EXPORT TO PDF -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Write your answer here, replacing this text.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Congratulations! You have finished Homework 4!##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# Submit\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output.\n",
    "**Please save before submitting!**\n",
    "\n",
    "<!-- EXPECT 11 EXPORTED QUESTIONS -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Save your notebook first, then run this cell to submit.\n",
    "import jassign.to_pdf\n",
    "jassign.to_pdf.generate_pdf('hw4.ipynb', 'hw4.pdf')\n",
    "ok.submit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
