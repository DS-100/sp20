{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees and Random Forests\n",
    "\n",
    "This notebook is a revised version of the [oustanding lecture notebook](http://data100.datahub.berkeley.edu/hub/user-redirect/git-sync?repo=https://github.com/DS-100/fa19-public-archive&subPath=lecture/lec25/lec25-decision-trees.ipynb) by Professor Hug.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "As with other notebooks we will use the same set of standard imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "np.random.seed(23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.offline as py\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.figure_factory as ff\n",
    "import cufflinks as cf\n",
    "cf.set_config_file(offline=True, sharing=False, theme='ggplot');\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Data\n",
    "\n",
    "For this notebook we will use the classic [Iris Dataset](https://en.wikipedia.org/wiki/Iris_flower_data_set).  The goal is to predict the species of [Iris](https://en.wikipedia.org/wiki/Iris_(plant)) based on measurements of the flower. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "column_names = [n.replace(\"(cm)\", \"\").strip() for n in iris['feature_names']]\n",
    "iris_data = pd.DataFrame(iris['data'], columns=column_names)\n",
    "iris_data['species'] = iris['target_names'][iris['target']]\n",
    "iris_data['target'] = iris['target']\n",
    "iris_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(iris_data, x=\"petal length\", y=\"petal width\", color=\"species\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that there are **three classes** of flower. This is a not a binary classification problem but instead a **multiclass classification problem**.  There are several  simple extensions of the logistic regression model to support multiple classes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiclass Logistic Regression\n",
    "\n",
    "The logistic regression model can be extended to multiple classes using several techniques.  Perhaps the simplest is the **one-versus-rest** approach where the multiclass prediction problem is divided into separate binary prediction problems. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_setosa = LogisticRegression(solver='lbfgs')\n",
    "lr_setosa.fit(iris_data[['petal length', 'petal width']], \n",
    "              iris_data['species'] == 'setosa')\n",
    "\n",
    "lr_versicolor = LogisticRegression(solver='lbfgs')\n",
    "lr_versicolor.fit(iris_data[['petal length', 'petal width']], \n",
    "                  iris_data['species'] == 'versicolor')\n",
    "\n",
    "lr_virginica = LogisticRegression(solver='lbfgs')\n",
    "lr_virginica.fit(iris_data[['petal length', 'petal width']], \n",
    "                iris_data['species'] == 'virginica');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_class(X):\n",
    "    most_likely_class = np.argmax(np.vstack([\n",
    "        lr_setosa.predict_proba(X)[:,1],\n",
    "        lr_versicolor.predict_proba(X)[:,1],\n",
    "        lr_virginica.predict_proba(X)[:,1]\n",
    "    ]), axis=0)\n",
    "    return iris['target_names'][most_likely_class]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_class(iris_data[['petal length', 'petal width']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How accurate is the model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = iris_data['species']\n",
    "Y_hat = predict_class(iris_data[['petal length', 'petal width']]) \n",
    "accuracy = np.mean(Y == Y_hat)\n",
    "print(\"Prediction Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-learn has a built-in implementation of one versus rest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model = LogisticRegression(multi_class = 'ovr', solver='lbfgs')\n",
    "lr_model.fit(iris_data[[\"petal length\", \"petal width\"]], \n",
    "             iris_data[\"species\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_hat = lr_model.predict(iris_data[['petal length', 'petal width']])\n",
    "accuracy = np.mean(Y == Y_hat)\n",
    "print(\"Prediction Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also visualize the predictions.  The following code constructs a plot illustrating the decision we would make for each possible value of `petal length` and `petal width`.  You don't need to understand the details of the code but the basic idea is evaluate the model on a grid (`mesgrid`) of features and color the plot the color the integer value for that feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_decision_boundaries(model, X, n=50):\n",
    "    categories, z_int = np.unique(Y, return_inverse=True)\n",
    "    # Make contour plot\n",
    "    u = np.linspace(X[:,0].min()-0.5, X[:,0].max()+0.5, n)\n",
    "    v = np.linspace(X[:,1].min()-0.5, X[:,1].max()+0.5, n)\n",
    "    us,vs = np.meshgrid(u, v)\n",
    "    X_test = np.c_[us.ravel(), vs.ravel()]\n",
    "    z_str = model.predict(X_test)\n",
    "    categories, z_int = np.unique(z_str, return_inverse=True)\n",
    "    return go.Contour(x=X_test[:,0], y=X_test[:,1], z=z_int, \n",
    "#                      contours=dict(start=0,end=2,size=1),\n",
    "                     colorscale=px.colors.qualitative.Plotly[:3],\n",
    "                     showscale=False,\n",
    "                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following plot we can see the data points and the predicted class assignment for all combinations of peta width and petal length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(iris_data, x=\"petal length\", y=\"petal width\", color=\"species\")\n",
    "fig.update_traces(marker=dict(size=12, line=dict(width=2, color='black')),\n",
    "                  selector=dict(mode='markers'))\n",
    "fig.add_trace(\n",
    "    plot_decision_boundaries(lr_model,\n",
    "                             iris_data[[\"petal length\", \"petal width\"]].to_numpy())\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Classification\n",
    "\n",
    "In lecture we introduced decision trees.  In this part of the notebook, we walk through the construction of a decision tree using scikit-learn.  The [scikit-learn decision tree overview](https://scikit-learn.org/stable/modules/tree.html) provides a good overview of decision trees and is worth skimming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "dt_model = tree.DecisionTreeClassifier()\n",
    "dt_model.fit(iris_data[[\"petal length\", \"petal width\"]], \n",
    "             iris_data[\"species\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that there are many hyperparameters that we can configure with decision trees.  The parameters that you may want to pay attention to are `max_depth` and `min_samples_split` which control overfitting.  `max_depth` determines how many times to divide the feature space (deeper models may overfit) and `min_samples_split` also determines the depth of the tree by preventing further splits when there are too few samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with logistic regression we can make predictions using the `predict` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_model.predict(iris_data[[\"petal length\", \"petal width\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the big advantages of decision trees is that they can be (assuming they are not too deep) interpretable while also fitting complex data.  The following code creates a visualization of the tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz\n",
    "dot_data = tree.export_graphviz(dt_model, out_file=None, \n",
    "                      feature_names=[\"petal length\", \"petal width\"],  \n",
    "                      class_names=[\"setosa\", \"versicolor\", \"virginica\"],  \n",
    "                      filled=True, rounded=True,  \n",
    "                      special_characters=True)  \n",
    "graph = graphviz.Source(dot_data)\n",
    "#graph.render(format=\"png\", filename=\"iris_tree\")\n",
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice at the first level that if $\\textbf{petal_width} \\leq 0.8$ then the iris is always a `setosa`.  Then as we move further down the tree we are able to split the data into leaf nodes of just one type.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you look carefully, you can find a leaf (leaf 7 from left to right) which has a value array that has non-zero entries in multiple classes.  Why didn't the leaf get further divided?  Let's examine that leaf more carefully.  We can extract the tree and identify the data with high impurity: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = dt_model.tree_\n",
    "leaves = t.apply(iris_data[[\"petal length\", \"petal width\"]].to_numpy().astype('float32'))\n",
    "impure_ind = t.impurity[leaves] > 0\n",
    "iris_data.loc[impure_ind, [\"petal length\", \"petal width\", \"species\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or, we can use the `predict_proba` function to return the prbabilities.  Note that only the impure leaves will will have probability less than 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "impure_ind = dt_model.predict_proba(iris_data[[\"petal length\", \"petal width\"]]).max(axis=1) < 1.\n",
    "iris_data.loc[impure_ind, [\"petal length\", \"petal width\", \"species\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In either case we see that it would not be possible to divide the leaf further since all the flowers have the same features but different classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also visualize the decision surface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(iris_data, x=\"petal length\", y=\"petal width\", color=\"species\")\n",
    "fig.update_traces(marker=dict(size=12,\n",
    "                              line=dict(width=2,\n",
    "                                        color='DarkSlateGrey')),\n",
    "                  selector=dict(mode='markers'))\n",
    "fig.add_trace(\n",
    "    plot_decision_boundaries(dt_model,\n",
    "                             iris_data[[\"petal length\", \"petal width\"]].to_numpy())\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the decision boundaries are **axis-aligned**.  Why is this?  Recall that we are dividing on one dimension at each node in the tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also compute the final accuracy using scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "predictions = dt_model.predict(iris_data[[\"petal length\", \"petal width\"]])\n",
    "accuracy_score(predictions, iris_data[\"species\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overfitting\n",
    "\n",
    "Let's examine overfitting with decision trees:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_iris_data, test_iris_data = train_test_split(iris_data, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sort so that the color labels match what we had in the earlier part of lecture\n",
    "train_iris_data = train_iris_data.sort_values(by=\"species\")\n",
    "test_iris_data = test_iris_data.sort_values(by=\"species\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "dt_model = tree.DecisionTreeClassifier()\n",
    "dt_model.fit(train_iris_data[[\"petal length\", \"petal width\"]], train_iris_data[\"species\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(train_iris_data, x=\"petal length\", y=\"petal width\", color=\"species\")\n",
    "fig.update_traces(marker=dict(size=12,\n",
    "                              line=dict(width=2,\n",
    "                                        color='DarkSlateGrey')),\n",
    "                  selector=dict(mode='markers'))\n",
    "fig.add_trace(\n",
    "    plot_decision_boundaries(dt_model,\n",
    "                             iris_data[[\"petal length\", \"petal width\"]].to_numpy())\n",
    ")\n",
    "fig.update_layout(title=\"Training Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(test_iris_data, x=\"petal length\", y=\"petal width\", color=\"species\")\n",
    "fig.update_traces(marker=dict(size=12,\n",
    "                              line=dict(width=2,\n",
    "                                        color='DarkSlateGrey')),\n",
    "                  selector=dict(mode='markers'))\n",
    "fig.add_trace(\n",
    "    plot_decision_boundaries(dt_model,\n",
    "                             iris_data[[\"petal length\", \"petal width\"]].to_numpy())\n",
    ")\n",
    "fig.update_layout(title=\"Test Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(dt_model.predict(train_iris_data[[\"petal length\", \"petal width\"]]), train_iris_data[\"species\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = dt_model.predict(test_iris_data[[\"petal length\", \"petal width\"]])\n",
    "accuracy_score(predictions, test_iris_data[\"species\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "sepal_dt_model = tree.DecisionTreeClassifier()\n",
    "sepal_dt_model.fit(train_iris_data[[\"sepal length\", \"sepal width\"]], train_iris_data[\"species\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data = iris_data, x = \"sepal length\", y=\"sepal width\", hue=\"species\", legend=False)\n",
    "fig = plt.gcf()\n",
    "fig.savefig(\"iris_scatter_plot_with_petal_data_sepal_only.png\", dpi=300, bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "sns_cmap = ListedColormap(np.array(sns.color_palette())[0:3, :])\n",
    "\n",
    "xx, yy = np.meshgrid(np.arange(4, 8, 0.02),\n",
    "                     np.arange(1.9, 4.5, 0.02))\n",
    "\n",
    "Z_string = sepal_dt_model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "categories, Z_int = np.unique(Z_string, return_inverse=True)\n",
    "Z_int = Z_int \n",
    "Z_int = Z_int.reshape(xx.shape)\n",
    "cs = plt.contourf(xx, yy, Z_int, cmap=sns_cmap)\n",
    "fig = plt.gcf()\n",
    "fig.savefig(\"iris_sepal_decision_boundaries_no_data.png\", dpi=300, bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "sns_cmap = ListedColormap(np.array(sns.color_palette())[0:3, :])\n",
    "\n",
    "xx, yy = np.meshgrid(np.arange(4, 8, 0.02),\n",
    "                     np.arange(1.9, 4.5, 0.02))\n",
    "\n",
    "Z_string = sepal_dt_model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "categories, Z_int = np.unique(Z_string, return_inverse=True)\n",
    "Z_int = Z_int \n",
    "Z_int = Z_int.reshape(xx.shape)\n",
    "cs = plt.contourf(xx, yy, Z_int, cmap=sns_cmap)\n",
    "sns.scatterplot(data = train_iris_data, x = \"sepal length\", y=\"sepal width\", hue=\"species\", legend=False)\n",
    "fig = plt.gcf()\n",
    "fig.savefig(\"iris_sepal_decision_boundaries_model_training_only.png\", dpi=300, bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "sns_cmap = ListedColormap(np.array(sns.color_palette())[0:3, :])\n",
    "\n",
    "xx, yy = np.meshgrid(np.arange(4, 8, 0.02),\n",
    "                     np.arange(1.9, 4.5, 0.02))\n",
    "\n",
    "Z_string = sepal_dt_model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "categories, Z_int = np.unique(Z_string, return_inverse=True)\n",
    "Z_int = Z_int \n",
    "Z_int = Z_int.reshape(xx.shape)\n",
    "cs = plt.contourf(xx, yy, Z_int, cmap=sns_cmap)\n",
    "sns.scatterplot(data = test_iris_data, x = \"sepal length\", y=\"sepal width\", hue=\"species\", legend=False)\n",
    "fig = plt.gcf()\n",
    "fig.savefig(\"iris_sepal_decision_boundaries_model_test_only.png\", dpi=300, bbox_inches = \"tight\")\n",
    "#fig = plt.gcf()\n",
    "#fig.savefig(\"iris_decision_boundaries_model_train_test_split.png\", dpi=300, bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_data = tree.export_graphviz(sepal_dt_model, out_file=None, \n",
    "                      feature_names=[\"sepal_length\", \"sepal_width\"],  \n",
    "                      class_names=[\"setosa\", \"versicolor\", \"virginica\"],  \n",
    "                      filled=True, rounded=True,  \n",
    "                      special_characters=True)  \n",
    "graph = graphviz.Source(dot_data)\n",
    "# graph.render(format=\"png\", filename=\"sepal_tree\")\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(sepal_dt_model.predict(train_iris_data[[\"sepal length\", \"sepal width\"]]), \n",
    "               train_iris_data[\"species\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(sepal_dt_model.predict(test_iris_data[[\"sepal length\", \"sepal width\"]]), \n",
    "               test_iris_data[\"species\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_model_4d = tree.DecisionTreeClassifier()\n",
    "all_features = [\"petal length\", \"petal width\", \"sepal length\", \"sepal width\"]\n",
    "dt_model_4d.fit(train_iris_data[all_features], train_iris_data[\"species\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = dt_model_4d.predict(train_iris_data[all_features])\n",
    "accuracy_score(predictions, train_iris_data[\"species\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = dt_model_4d.predict(test_iris_data[all_features])\n",
    "accuracy_score(predictions, test_iris_data[\"species\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_data = tree.export_graphviz(dt_model_4d, out_file=None, \n",
    "                      feature_names=all_features,  \n",
    "                      class_names=[\"setosa\", \"versicolor\", \"virginica\"],  \n",
    "                      filled=True, rounded=True,  \n",
    "                      special_characters=True)  \n",
    "graph = graphviz.Source(dot_data)\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.render(format=\"png\", filename=\"iris_4d_tree\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(x):\n",
    "    normalized_x = x / np.sum(x)\n",
    "    return sum(-normalized_x * np.log2(normalized_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "-np.log2(0.33)*0.33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "-np.log2(0.36)*0.36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "entropy([34, 36, 40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy([149, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy([50, 50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy([50, 50, 50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy([31, 4, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#entropy([50, 46, 3])\n",
    "#entropy([4, 47])\n",
    "#entropy([41, 50])\n",
    "#entropy([50, 50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_average_entropy(x1, x2):\n",
    "    N1 = sum(x1)\n",
    "    N2 = sum(x2)\n",
    "    N = N1/(N1 + N2)\n",
    "    return (N1 * entropy(x1) + N2 * entropy(x2)) / (N1 + N2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_average_entropy([50, 46, 3], [4, 47])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_average_entropy([50, 9], [41, 50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_average_entropy([2, 50, 50], [48])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_average_entropy([50, 50], [50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ten_decision_tree_models = []\n",
    "ten_training_sets = []\n",
    "for i in range(10):\n",
    "    current_model = tree.DecisionTreeClassifier()\n",
    "    temp_iris_training_data, temp_iris_test_data = np.split(iris_data.sample(frac=1), [110])\n",
    "    temp_iris_training_data = temp_iris_training_data.sort_values(\"species\")\n",
    "    current_model.fit(temp_iris_training_data[[\"sepal length\", \"sepal width\"]], temp_iris_training_data[\"species\"])\n",
    "    ten_decision_tree_models.append(current_model)\n",
    "    ten_training_sets.append(temp_iris_training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_decision_tree(decision_tree_model, data = None, disable_axes = False):\n",
    "    from matplotlib.colors import ListedColormap\n",
    "    sns_cmap = ListedColormap(np.array(sns.color_palette())[0:3, :])\n",
    "\n",
    "    xx, yy = np.meshgrid(np.arange(4, 8, 0.02),\n",
    "                     np.arange(1.9, 4.5, 0.02))\n",
    "\n",
    "    Z_string = decision_tree_model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    categories, Z_int = np.unique(Z_string, return_inverse=True)\n",
    "    Z_int = Z_int.reshape(xx.shape)\n",
    "    cs = plt.contourf(xx, yy, Z_int, cmap=sns_cmap)\n",
    "    if data is not None:\n",
    "        sns.scatterplot(data = data, x = \"sepal length\", y=\"sepal width\", hue=\"species\", legend=False)\n",
    "\n",
    "    if disable_axes:\n",
    "        plt.axis(\"off\")\n",
    "#    if disable_axes:\n",
    "#        \n",
    "#        plt.gca().xaxis.label.set_visible(False)\n",
    "#        plt.gca().yaxis.label.set_visible(False)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_num = 0\n",
    "plot_decision_tree(ten_decision_tree_models[m_num], ten_training_sets[m_num])\n",
    "plt.savefig(\"random_forest_model_1_example.png\", dpi = 300, bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_num = 7\n",
    "plot_decision_tree(ten_decision_tree_models[m_num], ten_training_sets[m_num])\n",
    "plt.savefig(\"random_forest_model_2_example.png\", dpi = 300, bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.gridspec as gridspec\n",
    "gs1 = gridspec.GridSpec(3, 3)\n",
    "gs1.update(wspace=0.025, hspace=0.025) # set the spacing between axes. \n",
    "\n",
    "for i in range(0, 9):\n",
    "    plt.subplot(gs1[i]) #3, 3, i)\n",
    "    plot_decision_tree(ten_decision_tree_models[i], None, True)    \n",
    "    \n",
    "plt.savefig(\"random_forest_model_9_examples.png\", dpi = 300, bbox_inches = \"tight\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
